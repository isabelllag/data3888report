---
title: "DATA3888 Report: Optiver 13"
format: html
editor: visual
---

## Executive Summary

The purpose of this project is to develop a model that accurately predicts volatility and to explain the model clearly to traders at Optiver. Our project has two key results. First, we found that SVM(Support Vector Machine) is most accurate for predicting the future volatility of most stocks, although ridge regression also performs well. Second, we deployed an interactive Shiny App to effectively communicate our results to traders.

This project is practically relevant because volatility is an essential component of the Black-Scholes equation, which is important for options pricing. Therefore, our results on optimizing model accuracy and improving model communication can help traders to make effective trading strategies.

## Aim and Background

**Aim**

Volatility is the degree of variation observed in the price of a financial instrument over time and is a key measure of market risk. For any trading firm including Optiver, volatility is crucial in option pricing and trading strategies.

The aim of this project is to find the model that offers the best tradeoff among prediction accuracy, model interpretability and model robustness, and to investigate the effects that input stocks have on model performance.

**Multidisciplinarity**

This project requires both finance and data science knowledge. From the financial perspective, understanding and predicting volatility is critical for successful trading strategies. From the data science standpoint, predicting volatility is a complicated task involving time series prediction, which is generally characterized by non-linear, non-stationary, and potentially high-dimensional data. The development of a reliable volatility prediction model would therefore require a deep understanding of both of these domains.

**Motivational background**

For any complex models, there is necessarily a tradeoff between predictive power and interpretability. Indeed, Optiver identifies such an issue, so they value a model\'s interpretability as much as its performance. Consequently, Optiver approached DATA3888 students to grapple with this tradeoff by developing a model to accurately predict volatility, and also effectively communicating that model to traders. \

Despite being a critical measure for trading, volatility is inherently difficult to predict. Traditional models like the GARCH model and its variants have limitations due to their assumptions and rigid structure. In this project, our group evaluated various models, from basic models like regression to deep learning models like LSTM, to find the best model for predicting volatility. At the same time, we are aware of the interpretability problem and aims to explain our model clearly.

## Method

### A. Data Science Perspective

The data for this project is the relevant stock datasets provided by Optiver. Our stock data consists of price, volume and time variables, including bid price, ask price, bid size, ask size, time id and seconds in each time id. 

After all models are trained, they were evaluated for their performance. This is done using a combination of graphical and quantitative method:

1.  Graphical: The plots used for evaluation include actual v.s. predicted linear plots, box plots of RMSE for each cluster, QLIKE box plots for each cluster, and ACF plots. These graphics provide a visual indication of how well the model is performing.

2.  Quantitative: Quantitative metrics provide a more direct assessment of the model's performance. For the task of predicting volatility, these might include metrics like Root Mean Squared Error (RMSE), and R-squared. 

We developed six models in this project: ARMA-GARCH, HAV-RV, SVM, Ridge Regression, Random Forest and LSTM.

**ARMA-GARCH**

ARMA-GARCH models are a combination of Autoregressive Moving Average (ARMA) and Generalised Autoregressive Conditional Heteroskedasticity (GARCH) models. ARMA models consist of an autoregressive element, which predicts future values based on past values, and a moving average element, which takes into account the errors from previous predictions. GARCH models predict the volatility of a time series. 

This model was chosen for this project because it is conventionally used by the finance industry to predict volatility. GARCH models with non-normal distributions are robust for predicting volatility (Liu and Morley).

The main assumption for the model is stationarity (see appendix). 

**HAV-RV**

The HAR-RV model (Heterogeneous Autoregressive Realized Volatility model) works directly on realized volatility to predict future volatility. Because this model is generally used for daily realized volatility while our data\'s time interval is much shorter, HAR-RV model in this project only serves as a benchmark. We used realized volatility for the previous time interval and the mean realized volatility for the past five time intervals to predict future volatility. Since stock datasets are highly complex, we used Weighted Least Square for prediction.

**SVM**

SVM model performs well with highly complex data. Since stock datasets are complicated, our group believe that SVM is an important model to be evaluated. Choosing a suitable kernel is crucial for SVM's performance, and we chose Radial Basis Function (RBF) because this works well for non-linear and complex relationships, such as predicting volatility in our case. However, downsides of RBF includes overfitting and high training time, which are important aspects for evaluation. 

**Ridge Regression**

Ridge regression is a regularized linear regression method, which is part of the elastic network of the generalized linear regression model and controls model complexity by introducing an L2 regularization term. Unlike ordinary linear regression, ridge regression adds a regularization term to the objective function, which is the product of the sum of the squares of the coefficients and a regularization parameter lambda. Ridge regressions requires tuning parameters. The parameter lambda determines the strength of model regularization, and a larger lambda means a stronger regularization. When performing model tuning, different lambda values are usually tried, and the best lambda value is selected through methods such as cross-validation. This is to find a balance between bias and variance to obtain a model with better generalization ability.

**LSTM**

The LSTM (Long Short-Term Memory) deep learning model is a type of recurrent neural network designed to capture long-term dependencies in sequential data. LSTMs have memory cells controlled by input, forget and output gates. This model is chosen when long-term dependencies are important. For our implementation, we defined the layers and the corresponding parameters, chose the fitness loss function to the model, trained the model using training datasets and finally used the validation data to adjust the prediction value. After all the epochs (like the iterative times), the model is trained and ready to be used.

**Random Forest**

A random forest model works by creating many decision trees, each of which is trained on a different subset of the data. The randomness comes from both choosing the subsets of data and choosing the subsets of features used for splitting each node in the tree. When making a prediction, random forest feeds the input data to each of the decision trees in the forest. Each tree gives a prediction independently from the others and decide a final results based on these independent predictions. 

Advantages of random forest include robustness and flexibility. Random forest is less likely to overfit because the model averages the results of many different trees. Random Forest can handle both linear and non-linear relationships between predictors and the target variable, which is useful because the relationship between various factors and market volatility is non-linear and highly complex.

### B. **Relevance to Industry Partner**

Predicting volatility is relevant to Optiver because volatility is an important element in the Black-Scholes equation, which is used for options pricing, as well as for understanding risk. 

ARMA-GARCH, HAR-RV and regression are conventionally used in the trading industry to predict volatility (cite). It was therefore relevant to Optiver to build and evaluate these models to either affirm or challenge their use by the firm, and to communicate these common models to traders. SVM, Random Forest, and LSTM are less commonly used; therefore, evaluating them and communicating them to traders was relevant to Optiver because there was scope to innovate upon the conventional models used in finance. 

Comparing a variety of models was relevant to Optiver because not only did it mean developing and explaining models to traders, but justifying them on the basis of their accuracy and time cost. The value of this method is that it enables traders to feel more confident in accepting the model as the optimal to use. Time was a particularly important evaluative element because traders must make decisions quickly in real-time; models with long runtimes, regardless of their accuracy, would be impractical for most trading environments. 

## Results

### A. Models

In the project, we need to evaluate the effectiveness of six distinct models across the six clusters of the stock data. We considered different strategies to evaluate our models for each cluster. There are three metrics that  we plan to use. They are  Root Mean Square Error (RMSE), the coefficient of determination (R\^2), and Mean Absolute Error (MAE). Among these metrics, we decide to use RMSE to estimate the accuracy of our models instead of MAE and R\^2. RMSE gauges the mean square magnitude of errors, it is more sensitive to outliers. This characteristic is particularly salient in the realm of financial data, which often harbors significant outliers and where the impact of sizable errors can be considerable. Contrastingly, the Mean Absolute Error (MAE) measures the absolute magnitude of errors,  it is less sensitive to outliers compared to RMSE. Also, we are not able to justify whether the error is positive or negative when we use MAE. But it is significant for volatility  to know its trends. These shortcomings also apply to R\^2. Even though R\^2  is good at providing  an overall measure of model fit, it fails to directly reflect the magnitude or direction of prediction errors.

Besides, we also test the training time of each model. Since we can see that the RMSE boxes are similar for each model in our boxplot. Therefore shorter training time of a model could be better in the rapidly changing stock market.

That's the mean of the RMSE of each model in each cluster. More information could be found in boxplots in the appendix. In this table, SVM and Ridge Regression performed better. But RMSE of SVM possessed a slightly dense distribution and fewer outliers in boxplots.

|                  |             |             |             |             |             |             |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
|                  | Cluster1    | Cluster2    | Cluster3    | Cluster4    | Cluster5    | Cluster6    |
| ARMA-GARCH       | 0.000397717 | 0.000397711 | 0.000397592 | 0.000397779 | 0.000397691 | 0.00049788  |
| SVM              | 0.000234895 | 0.000138351 | 0.000160307 | 0.000325224 | 0.000228932 | 0.00017798  |
| Ridge Regression | 0.000257502 | 0.000186632 | 1.80E-04    | 0.000314913 | 0.000248003 | 0.00026557  |
| LSTM             | 0.000307353 | 0.000529648 | 0.000259467 | 0.000631368 | 0.001059554 | 0.001005189 |
| Random Forest    | 0.000651958 | 4.27E-04    | 4.30E-04    | 7.86E-04    | 5.87E-04    | 6.07E-04    |
| HAV-RV           | 0.000788709 | 0.000546498 | 0.000570423 | 0.001038327 | 0.000775287 | 0.000700853 |

```{r}
library(readxl)
# Read excel file that contains RMSEs for each model in a cluster
final <-  read_excel("./dataset/result/C2.xlsx")
# Transfer some MSE to RMSE
final$LINEAR<- sqrt(final$LINEAR)
final$RF <- sqrt(final$RF)
# Process the data
final1 <- gather(final)
final1 <- na.omit(final1)
# We need to do it in cluster 6 since there is a super high RMSE in it.
d = which(final1$value == max(final1$value))
final1 = final1[-d,]
# Draw the boxplot
colors <- c("#0072B2", "#E69F00", "#009E73", "#F0E442", "#D55E00", "#CC79A7")
ggplot(final1, aes(x = key, y = value, fill = key)) +
  geom_boxplot(
    notch = TRUE,
    outlier.color = "black",
    outlier.shape = 16,
    width = 0.5
  ) +
  labs(x = "Models", y = "Rmse") +
  ggtitle("Boxplot for cluster6") +
  scale_fill_manual(values = colors) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 8),
    legend.position = "none",
    panel.background = element_rect(fill = "#F5F5F5")
  )
```

Also, We test the training time for each model using the same test data.

Generally, SVM and Ridge Regression are good for the data. And if you need a shorter training time of the model, Ridge Regression could be a better choice.

### B. Deployment

Before analyzing each stock data provided by Optiver, our group separated the datasets into different clusters. Because different stocks can have very different charateristics, clustering helps to identify these differences so that we can analyse the clusters individually and find the best model for a particular type of stock.  Given the financial nature of the datasets, our group decided to use liquidity - one of the most important metrics in stock trading - for clustering.\[1\] Liquidity measures how rapidly a stock can be bought or sold without significantly impacting its price, and we used the following formula to calculate liquidity:

liquidity= sum(mean(bid_size1),mean(bid_size2),mean(ask_size1),mean(ask_size2))

All data sets were clustered using liquidity as the metrics and K-means as the clustering method. We first selected 5 stocks with extremely high volatilities as outliers and categorised them into a separate cluster. Then, our group clustered the remaining stocks into 5 clusters, choosing 5 stocks from each cluster, for a total of 30 stocks to analyse. Besides the original variables, we also calculated WAP, Bidaskspread, number of orders, oversize and volatility (formulae below):

WAP=(bid_price1 \* ask_size1 + ask_price1 \* bid_size1)/(bid_size1 + ask_size1))

BidAskSpread = ask_price / bid_price-1

num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2

over_bid = sum(bid_size1) +sum(bid_size2)-sum(ask_size1)-sum(ask_size2)

volatility= √(〖sum(log⁡return)〗\^2 )

Since time id\'s are not sequential while seconds in time id\'s are sequential, our group divided the time within a time id to time intervals and calculated volatilities for each time interval. Each time id is roughly 600 seconds, with each time interval 30 seconds. After training and testing the model, our group calculated RMSE based on their data and organised the results into box-plots that are categorized according to different clusters and models. (Formula of RMSE shown below):

RMSE= √(〖mean((predicted -actual)〗\^2)) 

We communicate our group\'s product using R shiny app. Based on user\'s input, the app can display the RMSE boxplots of the 6 models for each cluster or a prediction vs actual plot of volatilises for the best model of the cluster. To help traders interpreting the model, we included a short description of the best model\'s working principles and justifications of why it is selected. Furthermore, the shiny app includes interactive feature that allows user to upload a stock csv file and predict volatilities immediately. The app will show the stock\'s liquidity, its assigned cluster based on liquidity, and using the best model for the particular cluster, our shiny app will produce a prediction vs actual plot generated from the selected model. This feature allows traders to directly assess our model\'s performance, thus assisting them to make decision on whether the model should be used.

## Discussion

Our group identifies three main shortcomings of our project and final product. First, our project is much more focused on the data science discipline, neglecting the implications of financial knowledge. For example, we use only one method of calculating volatility, namely the standard deviation of returns, without considering other methods like beta coefficient. This potentially leads to differences in our final evaluation of models as our models' performance may change depending on the method of volatility used. Second, our clustering of the dataset is possibly futile from hindsight. We clustered the stocks using liquidity; however, after evaluation, SVM(Support Vector Machine) ends up being the best model for the majority of the clusters. A potential reason for this is that our clustering is based on only one variable, i.e. liquidity, ignoring other characteristics of a stock. A better clustering using more variables can produce a different set of clusters, thus resulting in different model performance and final evaluation. Third, our group did not use feature selection, and we could have used selection criteria like AIC or BIC to choose the most important features. Such selection can reduce our training time, and potentially change our model performance, leading to different evaluation results.

## Conclusion

The aim of our project is to develop and communicate a model that accurately predicts stock volatility and can be interpreted clearly by traders. After initial preliminary calculations on the datasets, we organised them into six clusters and used six different models - ARMA-GARCH, SVM, Regression, HAR-RV, LSTM and Random Forest - for evaluation. Using RMSE as our main evaluation metric, we found the best models for each cluster and effectively communicated our findings using an illustrative ShinyApp. For future improvements, our group identified at least three areas:

1.  Using different methods of calculating volatility for comparison.

2.  Clustering the datasets using more features of the stocks.

3.  Feature selection of the variables used for training the models.

We believe that these future works will improve our model performance.

## Student Contributions

## References

\[1\] Ben R. Marshall, Martin Young Liquidity and stock returns in pure order-driven markets: evidence from the Australian stock market (2003) https://doi.org/10.1016/S1057-5219(03)00006-1

Wei Liu and Bruce Morley, 'Volatility in the Hang Seng Index using the GARCH Approach', Asia-Pacific Financial Markets 16:51-63 (2009) https://doi.org/10.1007/s10690-009-9086-4

## Appendix

1.  Here is the coding part for clustering stocks, stock selection, process of SVM model and production of RMSE box plots.

    ```{r, echo=FALSE}
    # Prepare work for clustering
    path <- "./data3888/Optiver/individual_book_train"
    names <- dir('./data3888/Optiver/individual_book_train')
    # Get the list of file names in the directory
    file_names <- list.files(path, pattern = ".csv", full.names = TRUE)
    n <- 1
    liquidity <- NULL
    # Loop through each file, read it into a data frame, and add it to the list
    for (file in file_names) {
      name <- names[n]
      n = n+1
      df <- read.csv(file)
      dff <- NULL
      # store stock names
      dff['name'] <- name
      # calculate liquidity for each stock 
      dff['liquidity'] <-round(sum(mean(df$bid_size1), mean(df$bid_size2),mean(df$ask_size1),mean(df$ask_size2)),0)
      liquidity <- rbind(liquidity,dff)
    }
    liquidity <- as.data.frame(liquidity)
    # load the liquidity file
    l <- read.csv('liquidity edited.csv')
    # Use kmean to cluster
    kmeans <- kmeans(l[2], centers = 5)







    samples_per_cluster <- 5
    cluster_labels <- kmeans$cluster
    # Initialize an empty list to store selected samples
    selected_samples <- NULL

    # Loop through each cluster
    for (i in 1:5) {
      # Extract samples belonging to the current cluster
      current_cluster_samples <- l[cluster_labels == i, , drop = FALSE]
      
      # Randomly select samples from the current cluster
      temp <- NULL
      temp <- current_cluster_samples[sample(nrow(current_cluster_samples), samples_per_cluster), , drop = T]
      temp['cluster'] <- i
      selected_samples <- rbind(selected_samples,temp)
    }

    # Combine the selected samples from all clusters into a single matrix
    selected_samples <- do.call(rbind, selected_samples)
    selected_samples <- as.data.frame(selected_samples)








    square <- function(x) {
      return(x^2)
    }
    #make a function for calculate RMSE
    Derek <- function(path,c) {
      # data prepare 
      s <- read.csv(path)
      s <- s %>% mutate(WAP = (bid_price1 * ask_size1 +
                                 ask_price1 * bid_size1) /
                          (bid_size1 +   ask_size1))
      data <- s %>% mutate(BidAskSpread = 
                             ask_price1 / bid_price1 - 1)
      data <- data %>%  mutate(time_bucket =
                                 ceiling(seconds_in_bucket / 30))
      lr <- c(data$WAP[1],diff(log(data$WAP)))
      lr = as.data.frame(lr)
      data <- cbind(data,lr)
      id <- unique(data$time_id)
      set.seed(c)
      selected_id = sample(id, size = 100, replace = F)
      results <- data.frame()
      # Train a model for each time id
      for (i in 1:length(selected_id)){
        k <- data.frame()
        d <- data %>% filter(time_id == selected_id[i])
        d = d[-1,]
        time <- unique(d$time_bucket)
        # Take variables we need for training 
        for (y in 1:length(time)){
          df <- NULL
          dt <- d %>% filter(time_bucket == time[y])
          df['time_id'] = selected_id[i]
          df['time_bucket'] = time[y]
          df['mean_WAP'] = mean(dt$WAP)
          df['mean_spread'] = mean(dt$BidAskSpread)
          df['voladility'] = sqrt(sum(square(dt$lr)))
          df = t(df)
          df = as.data.frame(df) 
          k <- rbind(df,k)
        }
        k <- k[order(k$time_bucket),]
        i_d = k$time_id[1]
        k = k[,-1]
        # Start to train
        train_control <- trainControl(method = "timeslice",
                                      initialWindow = 4,  
                                      horizon = 1,  
                                      fixedWindow = TRUE)
        svm_model <- train(voladility ~ ., data = k, method =
                             "svmRadial", trControl =train_control)
        # Take the RMSE
        result = data.frame(i_d, svm_model$results$RMSE[1])
        results = rbind(results,result)
        
      }
      return(results)
    }






    # Get RMSEs for each cluster and prepare data for creating Boxplots
    # Read cluster file we got from kmeans
    cluster <- read.csv('sample select.csv')
    n <- length(unique(cluster$cluster))
    df_list <- list()
    # Go through each cluster
      for (i in 1:n) {
        select <- cluster %>% filter(cluster == i)
        print(i)
        final <- data.frame()
        #Go through each stock we randomly picked from each cluster
        for (p in 1:length(select$X)) {
          path = paste('./data3888/Optiver/individual_book_train/',select$X[p], sep = "")
          
          # Get RMSE in the cluster
          rmse <- Derek(path,i)
          rmse['Name'] = select$X[p]
          final = rbind(final,rmse) 
        }
        df_list[[i]] = final
      }
      # Write them as CSV
      for (i in seq_along(df_list)) {
        write.csv(df_list[[i]], file = paste0("df", i, ".csv"), row.names = FALSE)
      }








    ```

### 
