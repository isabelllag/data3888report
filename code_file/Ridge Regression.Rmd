```{r, echo=TRUE, eval=FALSE, warning=FALSE, message=FALSE}
library(plyr)
library(tidyverse)
library(ggplot2)
library(leaflet)
library(dplyr)
library(data.table)
library(rugarch)
library(tensorflow)
library(keras)
library(caret)
library(kernlab)
library(stats)
```

```{r, echo=TRUE, eval=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyverse)
library(DT)
library(caret)
library(stats)
library(quantreg)
library(Metrics)
```

```{r}
data(Default, package = "ISLR")
```


```{r files dir}
dir1 <- "Cluster 1"
cluster1 <- list.files(dir1)
dir2 <- "Cluster 2"
cluster2 <- list.files(dir2)
dir3 <- "Cluster 3"
cluster3 <- list.files(dir3)
dir4 <- "Cluster 4"
cluster4 <- list.files(dir4)
dir5 <- "Cluster 5"
cluster5 <- list.files(dir5)
dir6 <- "Clsuter outlier"
cluster6 <- list.files(dir6)
```

```{r files list}
total_mse1 <- c()
mse_list1 <- c()
mse_list2 <- c()
mse_list3 <- c()
mse_list4 <- c()
mse_list5 <- c()
mse_list6 <- c()

count = 0

stock_file1 <- list()
for (i in cluster1) {
  stock_file1[[i]] <- read.csv(file.path(dir1, i))
}

stock_file2 <- list()
for (i in cluster2) {
  stock_file2[[i]] <- read.csv(file.path(dir2, i))
}

stock_file3 <- list()
for (i in cluster3) {
  stock_file3[[i]] <- read.csv(file.path(dir3, i))
}

stock_file4 <- list()
for (i in cluster4) {
  stock_file4[[i]] <- read.csv(file.path(dir4, i))
}

stock_file5 <- list()
for (i in cluster5) {
  stock_file5[[i]] <- read.csv(file.path(dir5, i))
}

stock_file6 <- list()
for (i in cluster6) {
  stock_file6[[i]] <- read.csv(file.path(dir6, i))
}
```

```{r cluster 1, warning=FALSE}
count = 0
total_mse1 <- c()
mse_list11 <- c()
mse_list12 <- c()
mse_list13 <- c()
mse_list14 <- c()
mse_list15 <- c()

for(i in 1 : length(stock_file1)){
  
  count = count + 1
  
  temporary <- stock_file1[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  set.seed(1)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1], 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1],
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility','price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    testing <- vol[[e]][-inTrain, ]
    
    glmnet1 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-18, 1e-10, length = 300)))
                   #tuneGrid = expand.grid(alpha = 0, lambda = 7.61524e-05))
    predicted <- predict(glmnet1, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    total_mse1 <- c(total_mse1, mse)
    if(count == 1){
      mse_list11 <- c(mse_list11, mse)
    }
    if(count == 2){
      mse_list12 <- c(mse_list12, mse)
    }
    if(count == 3){
      mse_list13 <- c(mse_list13, mse)
    }
    if(count == 4){
      mse_list14 <- c(mse_list14, mse)
    }
    if(count == 5){
      mse_list15 <- c(mse_list15, mse)
    }
  }
}
c(mean(total_mse1), sqrt(mean(total_mse1)))
```

```{r box1}
boxplot(total_mse1,horizontal = TRUE)
```

```{r cluster 2, warning=FALSE}
start_time <- Sys.time()


count = 0
total_mse2 <- c()
mse_list21 <- c()
mse_list22 <- c()
mse_list23 <- c()
mse_list24 <- c()
mse_list25 <- c()
r_squared_list <- c()
qlike <- c()
mae_list <- c()

for(i in 1 : length(stock_file2)){
  
  count = count + 1
  
  temporary <- stock_file2[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  
  
  
  set.seed(2)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1] , 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1] ,
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, 
                           price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility',
                            'price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    testing <- vol[[e]][-inTrain, ]
    
    glmnet2 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-8, 1e-1, length = 300)))
                   #tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-10, 1e-3, length = 300)))#seq(0.00000001, 10, length = 300)))
    predicted <- predict(glmnet2, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    
    corr <- cor(y_ture <- predicted, y_pred <- testing$volatility)
    r_squared <- corr^2
    r_squared_list <- c(r_squared_list, r_squared)
    
    qlike <- c(qlike, mean( testing$volatility /predicted   - log(testing$volatility/predicted) - 1))
    
    small_list <- c()
    
    for(z in (1:4)){
     small_list =  c(small_list, abs(predicted[[z]] - testing$volatility[[z]]))
    }
    
    mae_list <- c(mae_list, mean(small_list))
    
    total_mse2 <- c(total_mse2, mse)
    if(count == 1){
      mse_list21 <- c(mse_list21, mse)
    }
    if(count == 2){
      mse_list22 <- c(mse_list22, mse)
    }
    if(count == 3){
      mse_list23 <- c(mse_list23, mse)
    }
    if(count == 4){
      mse_list24 <- c(mse_list24, mse)
    }
    if(count == 5){
      mse_list25 <- c(mse_list25, mse)
    }
  }
}
end_time <- Sys.time()
c(mean(total_mse2), sqrt(mean(total_mse2)), mean(r_squared_list, na.rm = TRUE), end_time-start_time, mean(qlike, na.rm = TRUE), mean(mae_list, na.rm = TRUE))


```
```{r}
write.csv(r_squared_list, "r_squared.csv", row.names = FALSE)
write.csv(qlike, "qlike.csv", row.names = FALSE)
write.csv(mae_list, "mae.csv", row.names = FALSE)
```


```{r box2}
boxplot(total_mse2,horizontal = TRUE)
```

```{r cluster 3, warning=FALSE}
count = 0
total_mse3 <- c()
mse_list31 <- c()
mse_list32 <- c()
mse_list33 <- c()
mse_list34 <- c()
mse_list35 <- c()

for(i in 1 : length(stock_file3)){
  
  count = count + 1
  
  temporary <- stock_file3[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  set.seed(3)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1], 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1],
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, 
                           price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility',
                            'price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    testing <- vol[[e]][-inTrain, ]
    
    glmnet3 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-8, 1e-1, length = 300)))
                   #tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-10, 1e-3, length = 300))) #seq(0.00000001, 10, length = 300)))
    predicted <- predict(glmnet3, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    total_mse3 <- c(total_mse3, mse)
    if(count == 1){
      mse_list31 <- c(mse_list31, mse)
    }
    if(count == 2){
      mse_list32 <- c(mse_list32, mse)
    }
    if(count == 3){
      mse_list33 <- c(mse_list33, mse)
    }
    if(count == 4){
      mse_list34 <- c(mse_list34, mse)
    }
    if(count == 5){
      mse_list35 <- c(mse_list35, mse)
    }
  }
}
c(mean(total_mse3), sqrt(mean(total_mse3)))
```


```{r box3}
boxplot(total_mse3,horizontal = TRUE)
```

```{r cluster 4, warning=FALSE}
count = 0
total_mse4 <- c()
mse_list41 <- c()
mse_list42 <- c()
mse_list43 <- c()
mse_list44 <- c()
mse_list45 <- c()

for(i in 1 : length(stock_file4)){
  
  count = count + 1
  
  temporary <- stock_file4[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  set.seed(4)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1], 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1],
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, 
                           price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility',
                            'price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    training <- training[, !colnames(training) %in% "time_bucket"]
    testing <- vol[[e]][-inTrain, ]
    testing <- testing[, !colnames(testing) %in% "time_bucket"]
    
    glmnet4 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = 7.61524e-05)) #seq(1e-10, 1e-3, length = 300) 7.61524e-05
    predicted <- predict(glmnet4, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    total_mse4 <- c(total_mse4, mse)
    if(count == 1){
      mse_list41 <- c(mse_list41, mse)
    }
    if(count == 2){
      mse_list42 <- c(mse_list42, mse)
    }
    if(count == 3){
      mse_list43 <- c(mse_list43, mse)
    }
    if(count == 4){
      mse_list44 <- c(mse_list44, mse)
    }
    if(count == 5){
      mse_list45 <- c(mse_list45, mse)
    }
  }
}
c(mean(total_mse4), sqrt(mean(total_mse4)))
```


```{r box4}
boxplot(total_mse4,horizontal = TRUE)
```


```{r cluster 5, warning=FALSE}
count = 0
total_mse5 <- c()
mse_list51 <- c()
mse_list52 <- c()
mse_list53 <- c()
mse_list54 <- c()
mse_list55 <- c()

for(i in 1 : length(stock_file5)){
  
  count = count + 1
  
  temporary <- stock_file5[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  set.seed(5)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1], 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1],
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, 
                           price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility',
                            'price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    testing <- vol[[e]][-inTrain, ]
    
    glmnet5 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-8, 1e-1, length = 300)))
                   
    predicted <- predict(glmnet5, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    total_mse5 <- c(total_mse5, mse)
    if(count == 1){
      mse_list51 <- c(mse_list51, mse)
    }
    if(count == 2){
      mse_list52 <- c(mse_list52, mse)
    }
    if(count == 3){
      mse_list53 <- c(mse_list53, mse)
    }
    if(count == 4){
      mse_list54 <- c(mse_list54, mse)
    }
    if(count == 5){
      mse_list55 <- c(mse_list55, mse)
    }
  }
}
c(mean(total_mse5), sqrt(mean(total_mse5)))
```


```{r box5}
boxplot(total_mse5,horizontal = TRUE)
```

```{r cluster 6, warning=FALSE}
count = 0
total_mse6 <- c()
total_qlk6 <- c()
mse_list61 <- c()
mse_list62 <- c()
mse_list63 <- c()
mse_list64 <- c()
mse_list65 <- c()

for(i in 1 : length(stock_file6)){
  
  count = count + 1
  
  temporary <- stock_file6[[i]]
  
  temporary <- temporary %>% mutate(
    WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1))
  temporary <- temporary %>% mutate(BidAskSpread1 = ask_price1 / bid_price1 - 1)
  #temporary <- temporary %>% mutate(BidAskSpread2 = ask_price2 / bid_price2 - 1)
  temporary <- temporary %>% mutate(num_order = bid_size1 + ask_size1 + bid_size2 + ask_size2)
  
  set.seed(6)
  log_r1 <- list()
  time_IDs <- unique(temporary[, 1])
  sample_time_id = sample(time_IDs, 100, replace = FALSE)
  
  for (a in 1 : length(sample_time_id)) {
    sec <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(seconds_in_bucket) #对于sample_time_id             中的每个元素，获取 stock1 数据集中 time_id 列等于该元素的行的秒数。
    BS1 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread1)
    #BS2 <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(BidAskSpread2)
    order <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(num_order)
    price <- temporary %>% filter(time_id == sample_time_id[a]) %>% pull(WAP) 
    log_r <- log(price[-1] / price[1:(length(price) - 1)]) #使用所选行的 WAP 列计算对数收益率
    log_r1[[a]] <- data.frame(time = sec[-1], 
                              price = price[-1], 
                              BidAskSpread1= BS1[-1], 
                              #BidAskSpread2 = BS2[-1],
                              num_order = order[-1],
                              log_return = log_r)#将对数收益率存储在一个名为 log_r1 的列表中。
    
    time.no.change <- (1:600)[!(1:600 %in% log_r1[[a]]$time)]
    if (length(time.no.change) > 0) { #如果所选的时间戳没有连续的秒数数据，补充缺失的秒数数据，并将对数收益率设置为 0。
      new.df <- data.frame(time = time.no.change, 
                           price = 0, 
                           BidAskSpread1 = 0, 
                           #BidAskSpread2 = 0, 
                           num_order = 0, 
                           log_return = 0)
      log_r1[[a]] <- rbind(log_r1[[a]], new.df)
      log_r1[[a]] <- log_r1[[a]][order(log_r1[[a]]$time), ]
    }
  }
  
  vol <- list()
  comp_vol <- function(x) {
    return(sqrt(sum(x ^ 2)))
  }
  comp_price <- function(x) {
    return((sum(x))/length(x))
  }
  for (b in 1 : length(log_r1)) {
    log_r1[[b]] <- log_r1[[b]] %>% mutate(time_bucket = ceiling(time / 30))
    vol[[b]] <- aggregate(log_return ~ time_bucket, data = log_r1[[b]], FUN = comp_vol)
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(price ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread1 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    #vol[[b]] <- vol[[b]] %>% mutate(aggregate(BidAskSpread2 ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    vol[[b]] <- vol[[b]] %>% mutate(aggregate(num_order ~ time_bucket, data = log_r1[[b]], FUN = comp_price))
    colnames(vol[[b]]) <- c('time_bucket', 
                            'volatility',
                            'price', 
                            'BidAskSpread1', 
                            #'BidAskSpread2', 
                            'num_order' )
  }
  
  
  for(e in 1: length(vol)){
    inTrain <- createDataPartition(y=vol[[e]]$volatility,p=0.8,list=FALSE)
    training <- vol[[e]][inTrain, ]
    testing <- vol[[e]][-inTrain, ]
    
    glmnet6 <- train(volatility ~ ., data = training, method = "glmnet",
                   trControl = trainControl(method = "cv"),
                   tuneGrid = expand.grid(alpha = 0, lambda = seq(1e-8, 1e-1, length = 300)))
                   
    predicted <- predict(glmnet6, newdata = testing)
    mse <- mean((predicted - testing$volatility)^2)
    model_summary <- summary(glmnet6)
    
    LossVol(testing$volatility, predicted, which = "SE1")
    
    #rsquared <- model_summary$r.squared
    total_mse6 <- c(total_mse6, mse)
    if(count == 1){
      mse_list61 <- c(mse_list61, mse)
    }
    if(count == 2){
      mse_list62 <- c(mse_list62, mse)
    }
    if(count == 3){
      mse_list63 <- c(mse_list63, mse)
    }
    if(count == 4){
      mse_list64 <- c(mse_list64, mse)
    }
    if(count == 5){
      mse_list65 <- c(mse_list65, mse)
    }
  }
}
c(mean(total_mse6), mean(sqrt(total_mse6), mean(total_qlk6)))
```


```{r box6}
boxplot(total_mse6,horizontal = TRUE)
```


```{r total boxplot}
boxplot(total_mse1, 
        total_mse2,
        total_mse3, 
        total_mse4,
        total_mse5, 
        total_mse6,
        horizontal = TRUE)
```

```{r removing residuals}
filtered_data1 <- subset(sqrt(total_mse1), 
                        sqrt(total_mse1) >= quantile(sqrt(total_mse1), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse1), 0.75)-quantile(sqrt(total_mse1), 0.25))
                        & 
                        sqrt(total_mse1) <= quantile(sqrt(total_mse1), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse1), 0.75)-quantile(sqrt(total_mse1), 0.25)))
filtered_data2 <- subset(sqrt(total_mse2), 
                        sqrt(total_mse2) >= quantile(sqrt(total_mse2), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse2), 0.75)-quantile(sqrt(total_mse2), 0.25))
                        & 
                        sqrt(total_mse2) <= quantile(sqrt(total_mse2), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse2), 0.75)-quantile(sqrt(total_mse2), 0.25)))
filtered_data3 <- subset(sqrt(total_mse3), 
                        sqrt(total_mse3) >= quantile(sqrt(total_mse3), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse3), 0.75)-quantile(sqrt(total_mse3), 0.25))
                        & 
                        sqrt(total_mse3) <= quantile(sqrt(total_mse3), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse3), 0.75)-quantile(sqrt(total_mse3), 0.25)))
filtered_data4 <- subset(sqrt(total_mse4), 
                        sqrt(total_mse4) >= quantile(sqrt(total_mse4), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse4), 0.75)-quantile(sqrt(total_mse4), 0.25))
                        & 
                        sqrt(total_mse4) <= quantile(sqrt(total_mse4), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse4), 0.75)-quantile(sqrt(total_mse4), 0.25)))
filtered_data5 <- subset(sqrt(total_mse5), 
                        sqrt(total_mse5) >= quantile(sqrt(total_mse5), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse5), 0.75)-quantile(sqrt(total_mse5), 0.25))
                        & 
                        sqrt(total_mse5) <= quantile(sqrt(total_mse5), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse5), 0.75)-quantile(sqrt(total_mse5), 0.25)))
filtered_data6 <- subset(sqrt(total_mse6), 
                        sqrt(total_mse6) >= quantile(sqrt(total_mse6), 0.25) - 1.5 * 
                          (quantile(sqrt(total_mse6), 0.75)-quantile(sqrt(total_mse6), 0.25))
                        & 
                        sqrt(total_mse6) <= quantile(sqrt(total_mse6), 0.75) + 1.5 * 
                          (quantile(sqrt(total_mse6), 0.75)-quantile(sqrt(total_mse6), 0.25)))


boxplot(filtered_data1,filtered_data2,filtered_data3,filtered_data4,filtered_data5,filtered_data6, main = "RMSE for each cluster")
```
```{r}
write.csv(total_mse1, "pred1.csv", row.names = FALSE)
write.csv(total_mse2, "pred2.csv", row.names = FALSE)
write.csv(total_mse3, "pred3.csv", row.names = FALSE)
write.csv(total_mse4, "pred4.csv", row.names = FALSE)
write.csv(total_mse5, "pred5.csv", row.names = FALSE)
write.csv(total_mse6, "pred6.csv", row.names = FALSE)
```

```{r}
write.csv(filtered_data1, "pred1.csv", row.names = FALSE)
write.csv(filtered_data2, "pred2.csv", row.names = FALSE)
write.csv(filtered_data3, "pred3.csv", row.names = FALSE)
write.csv(filtered_data4, "pred4.csv", row.names = FALSE)
write.csv(filtered_data5, "pred5.csv", row.names = FALSE)
write.csv(filtered_data6, "pred6.csv", row.names = FALSE)
```






