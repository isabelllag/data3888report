---
title: "DATA3888 Report: Optiver 13"
format: html
editor: visual
---

## Aim and Background

**Aim**

Financial markets exhibit a high degree of uncertainty and risk, making it a challenging environment for both individual investors and financial institutions. Optiver, as a leading global market maker, specializes in creating fair, orderly, and efficient markets in a variety of financial instruments. One critical aspect that characterizes the behavior of these financial markets is 'volatility'. Volatility refers to the degree of variation observed in the price of a financial instrument over time and is a key measure of market risk.

The aim of this project is to find the model that offers the best tradeoff among accuracy, interpretability and robustness, and to investigate the effects that input stocks have on the model performance.

**Multidisciplinarity**

This project lies at the intersection of finance and data science. From the perspective of finance, understanding and predicting volatility is key to efficient portfolio management and risk mitigation. From the data science standpoint, this task represents a complex problem of time series prediction, which is generally characterized by non-linear, non-stationary, and potentially high-dimensional data. The development of a reliable volatility prediction model would therefore require a deep understanding of both these domains.

**Motivational background**

When developing models to predict volatility, there is necessarily a tradeoff between predictive power and interpretability. Indeed, Optiver identified an issue with their capacity to encourage traders to use more complex volatility models, because traders struggled to understand and therefore implement those models. Consequently, Optiver approached DATA3888 students at the University of Sydney to grapple with this tradeoff by developing a model to predict volatility, and effectively communicating that model to traders. 

As market makers, Optiver needs to quote prices at which they are willing to buy and sell financial instruments. These prices are largely influenced by the anticipated market volatility. High volatility increases the risk of market making and requires wider spreads, while low volatility allows for tighter spreads. Thus, the ability to accurately predict volatility is directly linked to Optiver's market making profitability.

Despite its significance, volatility is inherently unobservable and needs to be estimated from available market data. Traditional models like the GARCH model and its variants have limitations due to their assumptions and rigid structure. With the advent of machine learning techniques, there is potential to improve upon these traditional models by learning complex patterns from the data and offering superior predictive performance. Therefore, the generation of these models would represent a significant advancement in the profitability of the trading industry, and for Optiver in particular.

\

## Method

### A. Data Science Perspective

### B. Interdisciplinary Perspective

## Results

### A. Models

In the project, we need to evaluate the effectiveness of six distinct models across the six clusters of the stock data. We considered different strategies to evaluate our models for each cluster. There are three metrics that  we plan to use. They are  Root Mean Square Error (RMSE), the coefficient of determination (R\^2), and Mean Absolute Error (MAE). Among these metrics, we decide to use RMSE to estimate the accuracy of our models instead of MAE and R\^2. RMSE gauges the mean square magnitude of errors, it is more sensitive to outliers. This characteristic is particularly salient in the realm of financial data, which often harbors significant outliers and where the impact of sizeable errors can be considerable. Contrastingly, the Mean Absolute Error (MAE) measures the absolute magnitude of errors,  it is less sensitive to outliers compared to RMSE. Also, we are not able to justify whether the error is positive or negative when we used MAE. But it is significant for volatility  to know its trends. These shortcomings also apply to R\^2. Even though R\^2  is good at providing  an overall measure of model fit, it fails to directly reflect the magnitude or direction of prediction errors.

Besides, we also test the training time of each model. Since we can see that the RMSE boxes are similar for each model in our boxplot. Therefore shorter training time of a model could be better in the rapidly changing stock market.

### B. Deployment

## Discussion

Our group identifies three main shortcomings of our project and final product. First, our project is much more focused on the data science discipline, neglecting the implications of financial knowledge. For example, we use only one method of calculating volatility, namely the standard deviation of returns, without considering other methods like beta coefficient. This potentially leads to differences in our final evaluation of models as our models' performance may change depending on the method of volatility used. Second, our clustering of the dataset is possibly futile from hindsight. We clustered the stocks using liquidity; however, after evaluation, SVM(Support Vector Machine) ends up being the best model for the majority of the clusters. A potential reason for this is that our clustering is based on only one variable, i.e. liquidity, ignoring other characteristics of a stock. A better clustering using more variables can produce a different set of clusters, thus resulting in different model performance and final evaluation. Third, our group did not use feature selection, and we could have used selection criteria like AIC or BIC to choose the most important features. Such selection can reduce our training time, and potentially change our model performance, leading to different evaluation results.

## Conclusion

The aim of our project is to develop and communicate a model that accurately predicts stock volatility and can be interpreted clearly by traders. After initial preliminary calculations on the datasets, we organised them into six clusters and used six different models - ARMA-GARCH, SVM, Regression, HAR-RV, LSTM and Random Forest - for evaluation. Using RMSE as our main evaluation metric, we found the best models for each cluster and effectively communicated our findings using an illustrative ShinyApp. For future improvements, our group identified at least three areas:

1.  Using different methods of calculating volatility for comparison.

2.  Clustering the datasets using more features of the stocks.

3.  Feature selection of the variables used for training the models.

We believe that these future works will improve our model performance.

\

## Student Contributions

## References

## Appendix

### 
